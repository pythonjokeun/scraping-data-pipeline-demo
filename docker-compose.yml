version: "3"

services:

  # Scraper scheduler
  scraper-scheduler:
    build:
      context: ./scraper
      dockerfile: docker/scheduler/Dockerfile
    environment:
      - REQUEST_URL=https://219wx3mpv4-dsn.algolia.net/1/indexes/*/queries?x-algolia-application-id=219WX3MPV4&x-algolia-api-key=b528008a75dc1c4402bfe0d8db8b3f8e
      - DB_USER=[user]
      - DB_PASSWORD=[password]
      - DB_HOST=[host]
      - DB_PORT=[port]
      - DB_NAME=scraper
      - CRON_SCHEDULE="*/5 * * * *"
      - REDIS_URL=[host]
      - REDIS_PORT=[port]

  # Scraper consumer
  scraper-consumer:
    build:
      context: ./scraper
      dockerfile: docker/consumer/Dockerfile
    environment:
      - DB_USER=[user]
      - DB_PASSWORD=[password]
      - DB_HOST=[host]
      - DB_PORT=[port]
      - DB_NAME=scraper
      - REDIS_URL=[host]
      - REDIS_PORT=[port]

  # ETL data pipeline
  etl:
    build:
      context: ./etl
    environment:
      - DB_SCRAPER_URI=postgres://[user]:[password]@[host]:[password]/scraper
      - DB_ETL_URI=postgres://[user]:[password]@[host]:[password]/etl
      - CRON_SCHEDULE="*/5 * * * *"
